{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction\n",
    "12 clinical features for predicting death events.\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell # Importing so we can run multiple lines in one cell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Code so multiple lines in one cell can be ran simultaenously\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ▶  Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_failure_clinical_records_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is **DEATH_EVENT**.  \n",
    "We will try to predict **DEATH EVENT** using the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ▶  Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping DEATH_EVENT by age\n",
    "df.groupby(['age'], as_index=False)['DEATH_EVENT'].sum().sort_values(by='DEATH_EVENT', ascending=False)\n",
    "df.groupby(['diabetes'], as_index=False)['DEATH_EVENT'].sum().sort_values(by='DEATH_EVENT', ascending=False)\n",
    "df.groupby(['high_blood_pressure'], as_index=False)['DEATH_EVENT'].sum().sort_values(by='DEATH_EVENT', ascending=False)\n",
    "df.groupby(['smoking'], as_index=False)['DEATH_EVENT'].sum().sort_values(by='DEATH_EVENT', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of DEATH_EVENT\n",
    "sns.catplot(x='DEATH_EVENT', kind='count', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of DEATH_EVENT\n",
    "df['DEATH_EVENT'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our target class is imbalanced, it is only a 32.10% which is mild. We will leave it as-is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ▶  Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Treatment of Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Treatment of Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataframe Profile and export to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import numba\n",
    "\n",
    "profile_Report = ProfileReport(df, \n",
    "                               title=\"Heart Failure Prediction\",\n",
    "                               dataset={\n",
    "                                        \"description\": \"This profiling report was generated for the Heart Failure Prediction repository.\",\n",
    "                                        \"author\": \"Bader Ale\",\n",
    "                                        \"copyright_year\": 2024,\n",
    "                                        \"url\": \"https://github.com/baderale/WGU_MSDA\"}\n",
    "                               )\n",
    "\n",
    "\n",
    "profile_Report.to_widgets()\n",
    "profile_Report.to_file('Profile Report.html')\n",
    "print(numba.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ▶  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns are described as follows:\n",
    "1) age = age of patient\n",
    "2) anaemia = Decrease of red blood cells or hemoglobin (boolean)\n",
    "3) creatinine_phosphokinase = Level of the CPK enzyme in the blood (mcg/L)\n",
    "4) diabetes = If the patient has diabetes (boolean)\n",
    "5) ejection_fraction = Percentage of blood leaving the heart at each contraction (percentage)\n",
    "6) high_blood_pressure = If the patient has hypertension (boolean)\n",
    "7) platelets = Platelets in the blood (kiloplatelets/mL)\n",
    "8) serum_creatinine = Level of serum creatinine in the blood (mg/dL)\n",
    "9) serum_sodim = Level of serum sodium in the blood (mEq/L)\n",
    "10) sex =   Woman or man (binary)\n",
    "11) smoking = If the patient smokes or not (boolean)\n",
    "12) time = Follow-up period (days)\n",
    "13) DEATH_EVENT = If the patient deceased during the follow-up period (boolean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Set the number of rows and columns for subplots\n",
    "rows = min(len(num_cols), 4)\n",
    "cols = 4\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "\n",
    "# Flatten the axes array\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for each numeric column\n",
    "for i, col in enumerate(num_cols):\n",
    "    if i < len(axes):  # Ensure we only iterate over valid indices\n",
    "        axes[i].hist(df[col], bins=20)\n",
    "        axes[i].set_title(col)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise plots\n",
    "sns.pairplot(df, hue='DEATH_EVENT')\n",
    "plt.show()\n",
    "\n",
    "# Box plots for each variable against 'DEATH_EVENT'\n",
    "for column in df.columns:\n",
    "    if column != 'DEATH_EVENT':\n",
    "        sns.boxplot(x='DEATH_EVENT', y=column, data=df)\n",
    "        plt.show()\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## § Model - XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,y,test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# create model instance\n",
    "xgb_clf = XGBClassifier(n_estimators=15, max_depth=5, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Calculating accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, preds, target_names=df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## § Model - Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating feautres from targets\n",
    "df_features = df.drop('DEATH_EVENT', axis=1)\n",
    "df_target = df['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features before model\n",
    "df_features = StandardScaler().fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "model = SVC()\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an interpretation of the various metrics in the classification report:\n",
    "\n",
    "Precision:\n",
    "\n",
    "Precision for class 0: 0.75\n",
    "Precision for class 1: 0.76\n",
    "Precision measures the accuracy of positive predictions made by the model. For class 0, it means that 75% of the instances predicted as class 0 were actually class 0, and for class 1, it means that 76% of the instances predicted as class 1 were actually class 1.\n",
    "\n",
    "Recall:\n",
    "\n",
    "Recall for class 0: 0.89\n",
    "Recall for class 1: 0.54\n",
    "Recall, also known as sensitivity or true positive rate, measures the ability of the model to correctly identify all instances of a particular class. For class 0, it means that 89% of the actual class 0 instances were correctly identified, while for class 1, only 54% of the actual class 1 instances were correctly identified.\n",
    "\n",
    "F1-Score:\n",
    "\n",
    "F1-Score for class 0: 0.82\n",
    "F1-Score for class 1: 0.63\n",
    "The F1-Score is the harmonic mean of precision and recall and is a balanced metric that considers both false positives and false negatives. For class 0, the F1-Score is 0.82, indicating a good balance between precision and recall, while for class 1, the F1-Score is 0.63, which is lower due to the lower recall for this class.\n",
    "\n",
    "Support:\n",
    "\n",
    "Support for class 0: 55\n",
    "Support for class 1: 35\n",
    "The support represents the number of instances in each class in the dataset. In this case, there are 55 instances of class 0 and 35 instances of class 1.\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "Overall accuracy: 0.76\n",
    "The accuracy represents the proportion of correctly classified instances over the total number of instances. The overall accuracy of the model is 76%, which means that 76% of the instances in the dataset were correctly classified.\n",
    "\n",
    "Macro Average:\n",
    "\n",
    "Macro average precision: 0.76\n",
    "Macro average recall: 0.72\n",
    "Macro average F1-Score: 0.72\n",
    "The macro average calculates the precision, recall, and F1-Score by averaging the values for each class without considering class imbalance. In this case, the macro average precision, recall, and F1-Score are all around 0.72, indicating a moderate performance across both classes.\n",
    "\n",
    "Weighted Average:\n",
    "\n",
    "Weighted average precision: 0.76\n",
    "Weighted average recall: 0.76\n",
    "Weighted average F1-Score: 0.75\n",
    "The weighted average calculates the precision, recall, and F1-Score by considering the class imbalance in the dataset. It gives more weight to the class with more instances. In this case, the weighted average precision, recall, and F1-Score are all around 0.76, which is slightly higher than the macro average and indicates that the model's performance is more influenced by class 0 due to its higher support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## § Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['linear','rbf']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## § Model - Support Vector Classifier with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "model_tuned = SVC(C=1000, gamma=0.001, kernel='rbf')\n",
    "\n",
    "#Train the model using the training sets\n",
    "model_tuned.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_tuned = model_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report before and after tuning\n",
    "\n",
    "print('Before Tuning')\n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) \n",
    "\n",
    "print('\\n\\nAfter Tuning')\n",
    "predictions_tuned = model_tuned.predict(X_test) \n",
    "print(classification_report(y_test, y_pred_tuned)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and \"DEATH_EVENT\" is the target variable\n",
    "X = df.drop(\"DEATH_EVENT\", axis=1)\n",
    "y = df[\"DEATH_EVENT\"]\n",
    "\n",
    "# Create a classifier to use for feature selection\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the RFECV object\n",
    "rfecv = RFECV(estimator=classifier, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "\n",
    "# Fit the RFECV to the data\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "# Print the optimal number of features\n",
    "print('Optimal number of features: {}'.format(rfecv.n_features_))\n",
    "\n",
    "# Get the features selected by RFECV\n",
    "features = [f for f,s in zip(X.columns, rfecv.support_) if s]\n",
    "\n",
    "print('The selected features are: {}'.format(features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
